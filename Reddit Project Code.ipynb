{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import time\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InLineBackend.figure_format = 'retina'\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting Subreddits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be building a model to classify posts for the following subreddits: Physical Therapy and Chiropractic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting subreddit data from API\n",
    "res_1 = requests.get('https://api.pushshift.io/reddit/search/submission?subreddit=physicaltherapy')\n",
    "\n",
    "res_2 = requests.get('https://api.pushshift.io/reddit/search/submission?subreddit=personaltraining')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1: 200\n",
      "Response 2: 200\n"
     ]
    }
   ],
   "source": [
    "# Check for status of requests\n",
    "print('Response 1:', res_1.status_code)\n",
    "print('Response 2:', res_2.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read json objects into Python\n",
    "phys_th_json = res_1.json()\n",
    "pers_tr_json = res_2.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts: 25\n",
      "Number of posts: 25\n"
     ]
    }
   ],
   "source": [
    "# Check objects pulled in. Should be consistent with Reddit's 25 posts per pull limit.\n",
    "print('Number of posts:', len(phys_th_json['data']))\n",
    "print('Number of posts:', len(pers_tr_json['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting json to Pandas DataFrame\n",
    "phys_th_df = pd.DataFrame(phys_th_json['data'])\n",
    "pers_tr_df = pd.DataFrame(pers_tr_json['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['all_awardings', 'allow_live_comments', 'author',\n",
       "       'author_flair_css_class', 'author_flair_richtext', 'author_flair_text',\n",
       "       'author_flair_type', 'author_fullname', 'author_patreon_flair',\n",
       "       'author_premium', 'awarders', 'can_mod_post', 'contest_mode',\n",
       "       'created_utc', 'domain', 'full_link', 'gildings', 'id',\n",
       "       'is_crosspostable', 'is_meta', 'is_original_content',\n",
       "       'is_reddit_media_domain', 'is_robot_indexable', 'is_self', 'is_video',\n",
       "       'link_flair_background_color', 'link_flair_richtext',\n",
       "       'link_flair_text_color', 'link_flair_type', 'locked', 'media_only',\n",
       "       'no_follow', 'num_comments', 'num_crossposts', 'over_18',\n",
       "       'parent_whitelist_status', 'permalink', 'pinned', 'pwls',\n",
       "       'retrieved_on', 'score', 'selftext', 'send_replies', 'spoiler',\n",
       "       'stickied', 'subreddit', 'subreddit_id', 'subreddit_subscribers',\n",
       "       'subreddit_type', 'thumbnail', 'title', 'total_awards_received',\n",
       "       'treatment_tags', 'url', 'whitelist_status', 'wls', 'post_hint',\n",
       "       'preview', 'media', 'media_embed', 'removed_by_category',\n",
       "       'secure_media', 'secure_media_embed', 'thumbnail_height',\n",
       "       'thumbnail_width', 'media_metadata', 'author_flair_background_color',\n",
       "       'author_flair_text_color', 'edited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choosing PT subreddit features for model\n",
    "phys_th_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['all_awardings', 'allow_live_comments', 'author',\n",
       "       'author_flair_css_class', 'author_flair_richtext', 'author_flair_text',\n",
       "       'author_flair_type', 'author_fullname', 'author_patreon_flair',\n",
       "       'author_premium', 'awarders', 'can_mod_post', 'contest_mode',\n",
       "       'created_utc', 'domain', 'full_link', 'gildings', 'id',\n",
       "       'is_crosspostable', 'is_meta', 'is_original_content',\n",
       "       'is_reddit_media_domain', 'is_robot_indexable', 'is_self', 'is_video',\n",
       "       'link_flair_background_color', 'link_flair_richtext',\n",
       "       'link_flair_text_color', 'link_flair_type', 'locked', 'media_only',\n",
       "       'no_follow', 'num_comments', 'num_crossposts', 'over_18',\n",
       "       'parent_whitelist_status', 'permalink', 'pinned', 'pwls',\n",
       "       'retrieved_on', 'score', 'selftext', 'send_replies', 'spoiler',\n",
       "       'stickied', 'subreddit', 'subreddit_id', 'subreddit_subscribers',\n",
       "       'subreddit_type', 'thumbnail', 'title', 'total_awards_received',\n",
       "       'treatment_tags', 'url', 'whitelist_status', 'wls', 'post_hint',\n",
       "       'preview', 'link_flair_css_class', 'link_flair_template_id',\n",
       "       'link_flair_text', 'crosspost_parent', 'crosspost_parent_list',\n",
       "       'removed_by_category', 'thumbnail_height', 'thumbnail_width', 'media',\n",
       "       'media_embed', 'secure_media', 'secure_media_embed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choosing Chiro subreddit features for model\n",
    "pers_tr_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns of interest:\n",
    "mask = ['author', 'created_utc', 'is_self', 'num_comments', 'score', 'selftext', 'subreddit', 'title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract posts from subreddit with function:\n",
    "def get_posts(subreddit, kind, day_window, n_loops, size):\n",
    "    '''\n",
    "    1) Function takes subreddit name and endpoint parameters and constructs the URL for requests module to get a reponse.\n",
    "    2) day_window and n_loops allows you to specify the exact range of days from which you want to pull posts.\n",
    "    3) Size specifies the number of posts you want to pull per date range\n",
    "    '''\n",
    "    # Reddit Pushshift API primary endpoint\n",
    "    endpoint = f\"https://api.pushshift.io/reddit/search/{kind}\"\n",
    "    \n",
    "    # List to concatenate our DataFrames in\n",
    "    posts = []\n",
    "    \n",
    "    for i in range(1, n_loops + 1):\n",
    "        res = requests.get(endpoint,\n",
    "                           params={\n",
    "                               'subreddit': subreddit,\n",
    "                               'size': size,\n",
    "                               'after': f'{day_window*i}d'\n",
    "                           })\n",
    "    \n",
    "        print(f'Retrieved r/{subreddit} data from {day_window*i} days ago')\n",
    "        # Assert keyword to check for any errors in requests\n",
    "        assert res.status_code == 200\n",
    "        subreddit_json = res.json()['data']\n",
    "        # Convert json object to DataFrame\n",
    "        df = pd.DataFrame(subreddit_json)[mask]\n",
    "        posts.append(df)\n",
    "        # Prevent being DDOS flag\n",
    "        time.sleep(3)\n",
    "\n",
    "    final = pd.concat(posts)\n",
    "    \n",
    "    if kind == \"submission\":\n",
    "        \n",
    "        # Filter for columns of interest\n",
    "        final = final[mask]\n",
    "        \n",
    "        # Drop duplicates\n",
    "        final.drop_duplicates(inplace = True)\n",
    "        \n",
    "        # Filer for self posts\n",
    "        final = final.loc[final['is_self'] == True]\n",
    "    \n",
    "    final['date_created'] = final['created_utc'].map(dt.date.fromtimestamp)\n",
    "    \n",
    "    return final\n",
    "\n",
    "# Function adapted from lecture authored by Boom D. (DSI-NYC) and Mahdi Shadkam-Farrokhi (DSI-NYC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved r/physicaltherapy data from 50 days ago\n",
      "Retrieved r/physicaltherapy data from 100 days ago\n",
      "Retrieved r/physicaltherapy data from 150 days ago\n",
      "Retrieved r/physicaltherapy data from 200 days ago\n",
      "Retrieved r/physicaltherapy data from 250 days ago\n"
     ]
    }
   ],
   "source": [
    "# Reconstructing Phys. Therapy DataFrame to include posts from past 100 days\n",
    "phys_th_df = get_posts(subreddit = 'physicaltherapy', kind = 'submission', day_window = 50, n_loops = 5, size = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2003, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resetting index\n",
    "phys_th_df.reset_index(drop = True, inplace = True)\n",
    "# Checking final shape\n",
    "phys_th_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved r/personaltraining data from 50 days ago\n",
      "Retrieved r/personaltraining data from 100 days ago\n",
      "Retrieved r/personaltraining data from 150 days ago\n",
      "Retrieved r/personaltraining data from 200 days ago\n",
      "Retrieved r/personaltraining data from 250 days ago\n"
     ]
    }
   ],
   "source": [
    "# Reconstructing Personal Training DataFrame to include posts from past 100 days\n",
    "pers_tr_df = get_posts(subreddit = 'personaltraining', kind = 'submission', day_window = 50, n_loops = 5, size = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1245, 9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resetting index\n",
    "pers_tr_df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# Noticed the amount of data returned for the Personal Training subreddit \n",
    "# within the same 100 day time period is half the size of Phys. Therapy data\n",
    "pers_tr_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge both final version DataFrames together\n",
    "final_df = pd.concat([phys_th_df, pers_tr_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping redundant date record column\n",
    "final_df.drop(columns = 'created_utc', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3248, 8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape of DataFrame\n",
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author          0\n",
       "is_self         0\n",
       "num_comments    0\n",
       "score           0\n",
       "selftext        0\n",
       "subreddit       0\n",
       "title           0\n",
       "date_created    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check for null values and dropping them\n",
    "display(final_df.isna().sum())\n",
    "final_df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove posts with deleted or removed content.\n",
    "final_df = final_df[(final_df['selftext'] != '[deleted]') & (final_df['selftext'] != '[removed]')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to make sure all posts are original reddit posts.\n",
    "(final_df['is_self'] == True).sum() == final_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map numerical values to our classes \"subreddit\"\n",
    "final_df['subreddit'] = final_df['subreddit'].map({'physicaltherapy': 1, 'personaltraining': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Reset Index\n",
    "final_df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>is_self</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>date_created</th>\n",
       "      <th>all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dr_SidK</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>Hello, \\n\\nI am a neurologist with subspeciali...</td>\n",
       "      <td>1</td>\n",
       "      <td>A new, always free, online Parkinson’s Patient...</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>A new, always free, online Parkinson’s Patient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RichardSnell</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Goodmorning sirs and ma'ams.\\n\\nI am a recent ...</td>\n",
       "      <td>1</td>\n",
       "      <td>ATTENTION PHYSICAL THERAPISTS OF NEW ZEALAND</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>ATTENTION PHYSICAL THERAPISTS OF NEW ZEALAND G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stglidden</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[https://youtu.be/xtZ4sNGM5iM](https://youtu.b...</td>\n",
       "      <td>1</td>\n",
       "      <td>Scar tissue/adhesion of rectus femoris treatme...</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>Scar tissue/adhesion of rectus femoris treatme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vols52</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>I know this is probably a weird question, but ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Travel PT Question</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>Travel PT Question I know this is probably a w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>schiltron99</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>I have been away from sports because of a hams...</td>\n",
       "      <td>1</td>\n",
       "      <td>Heat or ice for damaged muscles?</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>Heat or ice for damaged muscles? I have been a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3034</th>\n",
       "      <td>nstrm</td>\n",
       "      <td>True</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>Hello personal trainers! 👋\\n\\nA few months ago...</td>\n",
       "      <td>0</td>\n",
       "      <td>I’m the developer of the weightlifting app Lif...</td>\n",
       "      <td>2019-10-05</td>\n",
       "      <td>I’m the developer of the weightlifting app Lif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3035</th>\n",
       "      <td>vikesfan50</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>I have a mock session with a client coming up....</td>\n",
       "      <td>0</td>\n",
       "      <td>Personal training mock client session.</td>\n",
       "      <td>2019-10-06</td>\n",
       "      <td>Personal training mock client session. I have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036</th>\n",
       "      <td>stupidstacker</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>Most of my business is referrals, but I’d like...</td>\n",
       "      <td>0</td>\n",
       "      <td>Studio owners - how do you find new leads?</td>\n",
       "      <td>2019-10-06</td>\n",
       "      <td>Studio owners - how do you find new leads? Mos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3037</th>\n",
       "      <td>Floopserino</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Im offering help for building a website. Why i...</td>\n",
       "      <td>0</td>\n",
       "      <td>Helping Out Personal Trainers With Websites an...</td>\n",
       "      <td>2019-10-06</td>\n",
       "      <td>Helping Out Personal Trainers With Websites an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3038</th>\n",
       "      <td>JazzyHustlah</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>How do you all employ marketing in your social...</td>\n",
       "      <td>0</td>\n",
       "      <td>Social Media Advice</td>\n",
       "      <td>2019-10-06</td>\n",
       "      <td>Social Media Advice How do you all employ mark...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3039 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             author  is_self  num_comments  score  \\\n",
       "0           Dr_SidK     True            13      1   \n",
       "1      RichardSnell     True             3      1   \n",
       "2         stglidden     True             1      1   \n",
       "3            vols52     True             4      1   \n",
       "4       schiltron99     True             2      1   \n",
       "...             ...      ...           ...    ...   \n",
       "3034          nstrm     True            60      3   \n",
       "3035     vikesfan50     True             7      3   \n",
       "3036  stupidstacker     True             9      8   \n",
       "3037    Floopserino     True             0      1   \n",
       "3038   JazzyHustlah     True             9     11   \n",
       "\n",
       "                                               selftext  subreddit  \\\n",
       "0     Hello, \\n\\nI am a neurologist with subspeciali...          1   \n",
       "1     Goodmorning sirs and ma'ams.\\n\\nI am a recent ...          1   \n",
       "2     [https://youtu.be/xtZ4sNGM5iM](https://youtu.b...          1   \n",
       "3     I know this is probably a weird question, but ...          1   \n",
       "4     I have been away from sports because of a hams...          1   \n",
       "...                                                 ...        ...   \n",
       "3034  Hello personal trainers! 👋\\n\\nA few months ago...          0   \n",
       "3035  I have a mock session with a client coming up....          0   \n",
       "3036  Most of my business is referrals, but I’d like...          0   \n",
       "3037  Im offering help for building a website. Why i...          0   \n",
       "3038  How do you all employ marketing in your social...          0   \n",
       "\n",
       "                                                  title date_created  \\\n",
       "0     A new, always free, online Parkinson’s Patient...   2020-03-05   \n",
       "1          ATTENTION PHYSICAL THERAPISTS OF NEW ZEALAND   2020-03-05   \n",
       "2     Scar tissue/adhesion of rectus femoris treatme...   2020-03-05   \n",
       "3                                    Travel PT Question   2020-03-05   \n",
       "4                      Heat or ice for damaged muscles?   2020-03-05   \n",
       "...                                                 ...          ...   \n",
       "3034  I’m the developer of the weightlifting app Lif...   2019-10-05   \n",
       "3035             Personal training mock client session.   2019-10-06   \n",
       "3036         Studio owners - how do you find new leads?   2019-10-06   \n",
       "3037  Helping Out Personal Trainers With Websites an...   2019-10-06   \n",
       "3038                                Social Media Advice   2019-10-06   \n",
       "\n",
       "                                               all_text  \n",
       "0     A new, always free, online Parkinson’s Patient...  \n",
       "1     ATTENTION PHYSICAL THERAPISTS OF NEW ZEALAND G...  \n",
       "2     Scar tissue/adhesion of rectus femoris treatme...  \n",
       "3     Travel PT Question I know this is probably a w...  \n",
       "4     Heat or ice for damaged muscles? I have been a...  \n",
       "...                                                 ...  \n",
       "3034  I’m the developer of the weightlifting app Lif...  \n",
       "3035  Personal training mock client session. I have ...  \n",
       "3036  Studio owners - how do you find new leads? Mos...  \n",
       "3037  Helping Out Personal Trainers With Websites an...  \n",
       "3038  Social Media Advice How do you all employ mark...  \n",
       "\n",
       "[3039 rows x 9 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge self-text and title features for vectorizers. We need a single vector in order for our vectorizers to do their job.\n",
    "final_df['all_text'] = final_df['title'] + ' ' + final_df['selftext']\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our X feature matrix and our y dependent variable vector\n",
    "X = final_df[['all_text', 'num_comments', 'score']]\n",
    "y = final_df['subreddit']\n",
    "\n",
    "# Train-Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since my classes are fairly imbalanced, I will perform oversampling on my minority class Physical Training \n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# RandomOverSampler is a tool used to inflate the minority class in our dataset - Uses random selection\n",
    "# algorithm that resamples data from the current minority class data WITH replacement until the classes are balanced.\n",
    "ros = RandomOverSampler(random_state = 42)\n",
    "X_resample, y_resample = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before resampling: \n",
      "1    0.646478\n",
      "0    0.353522\n",
      "Name: subreddit, dtype: float64\n",
      "\n",
      "After random oversampling: \n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: subreddit, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Compare results of over-sampling. Classes should now be balanced.\n",
    "print(f'Before resampling: \\n{y_train.value_counts(normalize = True)}')\n",
    "print()\n",
    "print(f'After random oversampling: \\n{y_resample.value_counts(normalize = True)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering and Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using make_column_transformer, I can transform both text data and my numerical features together\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer that also lemmatizes our text. Adapted from lecture authored by\n",
    "# Boom D. (DSI-NYC) and Mahdi S. (DSI-NYC)\n",
    "class LemmaTokenizer:\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc) if t.isalnum() and t not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    987\n",
       "0    533\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return model metrics\n",
    "def describe_model(gs, X_train, X_test, y_train, y_test):\n",
    "    '''\n",
    "    I've bundled some important classification metrics and visualizations for each model iteration. We're constructing\n",
    "    a confusion matrix, getting best parameters and accuracy scores as well as computing the ROC AUC.\n",
    "    '''\n",
    "    # Fit the model\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    preds = gs.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    cm_df = pd.DataFrame(cm, \n",
    "                         columns = ['Predicted Personal Training', 'Predicted Physical Therapy'],\n",
    "                         index = ['Actual Personal Training', 'Actual Physical Therapy'])\n",
    "    tn, fp, fn, tp = cm.ravel() # Extracting classification metrics\n",
    "    \n",
    "    # ROC AUC\n",
    "    pred_proba = [i[1] for i in gs.predict_proba(X_test)]\n",
    "    pred_df = pd.DataFrame({'true_values': y_test, 'pred_probs': pred_proba})\n",
    "    auc = roc_auc_score(y_test, pred_df['pred_probs'])\n",
    "    \n",
    "    # GridSearch Computations\n",
    "    print(f'Best Paramaters: {gs.best_params_}'\n",
    "          f'\\n\\nBest CV Score: {round(gs.best_score_, 2)}'\n",
    "          f'\\n\\nRaw Train Score: {round(gs.score(X_train, y_train), 2)}'\n",
    "          f'\\n\\nTest Performance: {round(gs.score(X_test, y_test), 2)}'\n",
    "          '\\n--------------------------------------------------------'\n",
    "          f'\\nSensitivity: {round(tp / (tp + fn), 2)}'\n",
    "          f'\\n\\nSpecificity: {round(tn / (tn + fp), 2)}'\n",
    "          f'\\n\\nPrecision: {round(tp / (tp + fp), 2)}'\n",
    "          f'\\n\\nAccuracy: {round((tp + tn) / (tp + fp + tn + fn), 2)}'\n",
    "          f'\\n\\nROC AUC Score: {round(auc, 2)}'\n",
    "         )\n",
    "    \n",
    "    return display(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Paramaters: {'mct_cvec__countvectorizer__max_features': 1500, 'mct_cvec__countvectorizer__ngram_range': (1, 2)}\n",
      "\n",
      "Best CV Score: 0.96\n",
      "\n",
      "Raw Train Score: 0.99\n",
      "\n",
      "Test Performance: 0.94\n",
      "--------------------------------------------------------\n",
      "Sensitivity: 0.96\n",
      "\n",
      "Specificity: 0.9\n",
      "\n",
      "Precision: 0.95\n",
      "\n",
      "Accuracy: 0.94\n",
      "\n",
      "ROC AUC Score: 0.98\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Personal Training</th>\n",
       "      <th>Predicted Physical Therapy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Personal Training</th>\n",
       "      <td>480</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Physical Therapy</th>\n",
       "      <td>42</td>\n",
       "      <td>945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Predicted Personal Training  \\\n",
       "Actual Personal Training                          480   \n",
       "Actual Physical Therapy                            42   \n",
       "\n",
       "                          Predicted Physical Therapy  \n",
       "Actual Personal Training                          53  \n",
       "Actual Physical Therapy                          945  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First model: CountVectorizer and standardized features with Logistic Regression\n",
    "\n",
    "# Instantiate column transformer object\n",
    "mct_cvec = make_column_transformer(\n",
    "        (CountVectorizer(max_df = .98, tokenizer = LemmaTokenizer()), 'all_text'),\n",
    "    (StandardScaler(), ['num_comments', 'score'])\n",
    ")\n",
    "\n",
    "# Instantiate Pipeline and GridSearchCV:\n",
    "pipe_1 = Pipeline([\n",
    "    ('mct_cvec', mct_cvec),\n",
    "    ('logreg', LogisticRegression(penalty = 'l1', solver = 'liblinear'))\n",
    "])\n",
    "\n",
    "# Select hyperparameters to tune:\n",
    "pipe_1_params = {\n",
    "    'mct_cvec__countvectorizer__ngram_range': [(1, 2), (2, 2), (2, 3)],\n",
    "    'mct_cvec__countvectorizer__max_features': [500, 1000, 1500],\n",
    "}\n",
    "\n",
    "# GridSearch with 5-fold CV\n",
    "gs_1 = GridSearchCV(pipe_1, param_grid = pipe_1_params, scoring = 'accuracy', cv =5)\n",
    "    \n",
    "\n",
    "# Evaluate Model 1\n",
    "describe_model(gs_1, X_resample, X_test, y_resample, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Physical Therapy Words: ['athletic', 'clinic', 'mobility', 'patient', 'pta']\n",
      "Top 5 Personal Training Words: ['client', 'fitness', 'nasm', 'trainer', 'training']\n"
     ]
    }
   ],
   "source": [
    "# For Model 1, identify the features with the highest coefficients.\n",
    "# Create a DataFrame of coefficients\n",
    "model_1_coefs = pd.DataFrame(pd.Series(gs_1.best_estimator_.named_steps['logreg'].coef_[0]).sort_values(ascending = False))\n",
    "\n",
    "# Extract feature names\n",
    "feature_names = gs_1.best_estimator_.named_steps.mct_cvec.named_transformers_.countvectorizer.get_feature_names()\n",
    "\n",
    "# List comp.\n",
    "print(f'Top 5 Physical Therapy Words: {[feature_names[idx] for idx, feature in enumerate(feature_names) if idx in model_1_coefs.head().index]}')\n",
    "print(f'Top 5 Personal Training Words: {[feature_names[idx] for idx, feature in enumerate(feature_names) if idx in model_1_coefs.tail().index]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Paramaters: {'mct_cvec__tfidfvectorizer__max_features': 500, 'mct_cvec__tfidfvectorizer__ngram_range': (1, 2)}\n",
      "\n",
      "Best CV Score: 0.94\n",
      "\n",
      "Raw Train Score: 0.96\n",
      "\n",
      "Test Performance: 0.95\n",
      "--------------------------------------------------------\n",
      "Sensitivity: 0.97\n",
      "\n",
      "Specificity: 0.91\n",
      "\n",
      "Precision: 0.95\n",
      "\n",
      "Accuracy: 0.95\n",
      "\n",
      "ROC AUC Score: 0.98\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Personal Training</th>\n",
       "      <th>Predicted Physical Therapy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Personal Training</th>\n",
       "      <td>483</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Physical Therapy</th>\n",
       "      <td>28</td>\n",
       "      <td>959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Predicted Personal Training  \\\n",
       "Actual Personal Training                          483   \n",
       "Actual Physical Therapy                            28   \n",
       "\n",
       "                          Predicted Physical Therapy  \n",
       "Actual Personal Training                          50  \n",
       "Actual Physical Therapy                          959  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Second model: TF-IDF and standardized features with Logistic Regression\n",
    "\n",
    "# Instantiate column transformer object\n",
    "mct_cvec = make_column_transformer(\n",
    "    (TfidfVectorizer(max_df = .98, tokenizer = LemmaTokenizer()), 'all_text'),\n",
    "    (StandardScaler(), ['num_comments', 'score'])\n",
    ")\n",
    "\n",
    "# Instantiate Pipeline and GridSearchCV:\n",
    "pipe_2 = Pipeline([\n",
    "    ('mct_cvec', mct_cvec),\n",
    "    ('logreg', LogisticRegression(penalty = 'l1', solver = 'liblinear'))\n",
    "])\n",
    "\n",
    "# Select hyperparameters to tune:\n",
    "pipe_2_params = {\n",
    "    'mct_cvec__tfidfvectorizer__ngram_range': [(1, 2), (2, 2), (2, 3)],\n",
    "    'mct_cvec__tfidfvectorizer__max_features': [500, 1000, 1500],\n",
    "}\n",
    "\n",
    "# GridSearch with 5-fold CV\n",
    "gs_2 = GridSearchCV(pipe_2, param_grid = pipe_2_params, scoring = 'accuracy', cv =5)\n",
    "    \n",
    "\n",
    "# Evaluate Model 2\n",
    "describe_model(gs_2, X_resample, X_test, y_resample, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Physical Therapy Words: ['clinic', 'pain', 'patient', 'pta', 'therapist']\n",
      "Top 5 Personal Training Words: ['client', 'fitness', 'nasm', 'trainer', 'training']\n"
     ]
    }
   ],
   "source": [
    "# For Model 2, identify the features with the highest coefficients.\n",
    "# Create a DataFrame of coefficients\n",
    "model_2_coefs = pd.DataFrame(pd.Series(gs_2.best_estimator_.named_steps['logreg'].coef_[0]).sort_values(ascending = False))\n",
    "\n",
    "# Extract feature names\n",
    "feature_names = gs_2.best_estimator_.named_steps.mct_cvec.named_transformers_.tfidfvectorizer.get_feature_names()\n",
    "\n",
    "# List comp.\n",
    "print(f'Top 5 Physical Therapy Words: {[feature_names[idx] for idx, feature in enumerate(feature_names) if idx in model_2_coefs.head().index]}')\n",
    "print(f'Top 5 Personal Training Words: {[feature_names[idx] for idx, feature in enumerate(feature_names) if idx in model_2_coefs.tail().index]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Paramaters: {'cvec__max_features': 1500, 'cvec__ngram_range': (1, 2)}\n",
      "\n",
      "Best CV Score: 0.96\n",
      "\n",
      "Raw Train Score: 0.99\n",
      "\n",
      "Test Performance: 0.94\n",
      "--------------------------------------------------------\n",
      "Sensitivity: 0.96\n",
      "\n",
      "Specificity: 0.9\n",
      "\n",
      "Precision: 0.95\n",
      "\n",
      "Accuracy: 0.94\n",
      "\n",
      "ROC AUC Score: 0.98\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Personal Training</th>\n",
       "      <th>Predicted Physical Therapy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Personal Training</th>\n",
       "      <td>480</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Physical Therapy</th>\n",
       "      <td>42</td>\n",
       "      <td>945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Predicted Personal Training  \\\n",
       "Actual Personal Training                          480   \n",
       "Actual Physical Therapy                            42   \n",
       "\n",
       "                          Predicted Physical Therapy  \n",
       "Actual Personal Training                          53  \n",
       "Actual Physical Therapy                          945  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Third model: CountVectorizer with LemmaTokenizer and L1 Penalty Logistic Regression (Text data ONLY)\n",
    "\n",
    "# Instantiate Pipeline and GridSearchCV:\n",
    "pipe_3 = Pipeline([\n",
    "    ('cvec', CountVectorizer(max_df = .98, tokenizer = LemmaTokenizer())),\n",
    "    ('logreg', LogisticRegression(penalty = 'l1', solver = 'liblinear'))\n",
    "])\n",
    "\n",
    "# Select hyperparameters to tune:\n",
    "pipe_3_params = {\n",
    "    'cvec__ngram_range': [(1, 2), (2, 2), (2, 3)],\n",
    "    'cvec__max_features': [500, 1000, 1500],\n",
    "}\n",
    "\n",
    "# GridSearch with 5-fold CV\n",
    "gs_3 = GridSearchCV(pipe_3, param_grid = pipe_3_params, scoring = 'accuracy', cv =5)\n",
    "    \n",
    "\n",
    "# Evaluate Model 3\n",
    "describe_model(gs_3, X_resample['all_text'], X_test['all_text'], y_resample, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Physical Therapy Words: ['athletic', 'clinic', 'mobility', 'patient', 'pta']\n",
      "Top 5 Personal Training Words: ['client', 'fitness', 'nasm', 'trainer', 'training']\n"
     ]
    }
   ],
   "source": [
    "# For Model 3, identify the features with the highest coefficients.\n",
    "# Create a DataFrame of coefficients\n",
    "model_3_coefs = pd.DataFrame(pd.Series(gs_3.best_estimator_.named_steps['logreg'].coef_[0]).sort_values(ascending = False))\n",
    "\n",
    "# Extract feature names\n",
    "feature_names = gs_3.best_estimator_.named_steps['cvec'].get_feature_names()\n",
    "\n",
    "# List comp.\n",
    "print(f'Top 5 Physical Therapy Words: {[feature_names[idx] for idx, feature in enumerate(feature_names) if idx in model_3_coefs.head().index]}')\n",
    "print(f'Top 5 Personal Training Words: {[feature_names[idx] for idx, feature in enumerate(feature_names) if idx in model_3_coefs.tail().index]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Paramaters: {'cvec__max_features': 1500, 'cvec__ngram_range': (1, 2), 'multi_nb__alpha': 1e-10}\n",
      "\n",
      "Best CV Score: 0.95\n",
      "\n",
      "Raw Train Score: 0.96\n",
      "\n",
      "Test Performance: 0.94\n",
      "--------------------------------------------------------\n",
      "Sensitivity: 0.95\n",
      "\n",
      "Specificity: 0.91\n",
      "\n",
      "Precision: 0.95\n",
      "\n",
      "Accuracy: 0.94\n",
      "\n",
      "ROC AUC Score: 0.97\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Personal Training</th>\n",
       "      <th>Predicted Physical Therapy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Personal Training</th>\n",
       "      <td>486</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Physical Therapy</th>\n",
       "      <td>50</td>\n",
       "      <td>937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Predicted Personal Training  \\\n",
       "Actual Personal Training                          486   \n",
       "Actual Physical Therapy                            50   \n",
       "\n",
       "                          Predicted Physical Therapy  \n",
       "Actual Personal Training                          47  \n",
       "Actual Physical Therapy                          937  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fourth model: TF-IDF (stopwords removed) with LemmaTokenizer and multinomial Naive Bayes (Text data ONLY)\n",
    "\n",
    "# Instantiate Pipeline and GridSearchCV:\n",
    "pipe_4 = Pipeline([\n",
    "    ('cvec', CountVectorizer(max_df = .98, tokenizer = LemmaTokenizer())),\n",
    "    ('multi_nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Select hyperparameters to tune:\n",
    "pipe_4_params = {\n",
    "    'cvec__ngram_range': [(1, 1), (1, 2)],\n",
    "    'cvec__max_features': [1000, 1500],\n",
    "    'multi_nb__alpha': np.linspace(1e-10, 1, 25)\n",
    "}\n",
    "\n",
    "# GridSearch with 5-fold CV\n",
    "gs_4 = GridSearchCV(pipe_4, param_grid = pipe_4_params, scoring = 'accuracy', cv =5)\n",
    "    \n",
    "\n",
    "# Evaluate Model #1\n",
    "describe_model(gs_4, X_resample['all_text'], X_test['all_text'], y_resample, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Physical Therapy Words: ['just', 'like', 'pain', 'patient', 'pt']\n",
      "Top 5 Personal Training Words: ['calorie', 'fitness professional', 'phd', 'pn level', 'user']\n"
     ]
    }
   ],
   "source": [
    "# For Model 4, identify the features with the highest coefficients.\n",
    "# Create a DataFrame of coefficients\n",
    "model_4_coefs = pd.DataFrame(pd.Series(gs_4.best_estimator_.named_steps['multi_nb'].coef_[0]).sort_values(ascending = False))\n",
    "\n",
    "# Extract feature names\n",
    "feature_names = gs_4.best_estimator_.named_steps['cvec'].get_feature_names()\n",
    "\n",
    "# List comp.\n",
    "print(f'Top 5 Physical Therapy Words: {[feature_names[idx] for idx, feature in enumerate(feature_names) if idx in model_4_coefs.head().index]}')\n",
    "print(f'Top 5 Personal Training Words: {[feature_names[idx] for idx, feature in enumerate(feature_names) if idx in model_4_coefs.tail().index]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
